{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/content\n",
            "Cloning into 'PML_FINAL_ASSIGNMENT'...\n",
            "remote: Enumerating objects: 12, done.\u001b[K\n",
            "remote: Counting objects: 100% (12/12), done.\u001b[K\n",
            "remote: Compressing objects: 100% (10/10), done.\u001b[K\n",
            "remote: Total 12 (delta 0), reused 12 (delta 0), pack-reused 0 (from 0)\u001b[K\n",
            "Receiving objects: 100% (12/12), 648.61 KiB | 22.37 MiB/s, done.\n",
            "/content/PML_FINAL_ASSIGNMENT\n"
          ]
        }
      ],
      "source": [
        "%cd /content\n",
        "!git clone https://github.com/GabrielSainz/PML_FINAL_ASSIGNMENT.git PML_FINAL_ASSIGNMENT\n",
        "%cd PML_FINAL_ASSIGNMENT"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "IRlfFpdW9CAm"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Device: cuda:0\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import torch\n",
        "from torchvision import datasets, transforms\n",
        "from torch.utils.data import DataLoader, random_split\n",
        "\n",
        "from exercise_1.utils.VAE import VAEConfig, train_vae\n",
        "\n",
        "# -------------------------\n",
        "# Device\n",
        "# -------------------------\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(\"Device:\", device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "root_path=\"/content/drive/MyDrive/University_of_Copenhagen/block6/PML/final_assignment/exercise_1\" "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "z29iBLP492dt"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 9.91M/9.91M [00:00<00:00, 17.9MB/s]\n",
            "100%|██████████| 28.9k/28.9k [00:00<00:00, 484kB/s]\n",
            "100%|██████████| 1.65M/1.65M [00:00<00:00, 4.53MB/s]\n",
            "100%|██████████| 4.54k/4.54k [00:00<00:00, 17.6MB/s]\n"
          ]
        }
      ],
      "source": [
        "batch_size = 128\n",
        "val_split = 0.1\n",
        "num_workers = 2\n",
        "\n",
        "transform = transforms.ToTensor()  # required for BCE loss in vae.py\n",
        "\n",
        "dataset_full = datasets.MNIST(f\"{root_path}/mnist_data\", download=True, train=True, transform=transform)\n",
        "n_val = int(len(dataset_full) * val_split)\n",
        "n_train = len(dataset_full) - n_val\n",
        "dataset_train, dataset_val = random_split(dataset_full, [n_train, n_val])\n",
        "\n",
        "dataloader_train = DataLoader(dataset_train, batch_size=batch_size, shuffle=True,\n",
        "                              num_workers=num_workers, pin_memory=True)\n",
        "dataloader_val = DataLoader(dataset_val, batch_size=batch_size, shuffle=False,\n",
        "                            num_workers=num_workers, pin_memory=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Beta-VAE "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OJNc8o2u-Dk7"
      },
      "outputs": [],
      "source": [
        "# -------------------------\n",
        "# Experiment grid\n",
        "# -------------------------\n",
        "latent_dims = [2, 16]\n",
        "betas = [0.01, 0.1, 1.0]\n",
        "\n",
        "# Training knobs (shared)\n",
        "epochs = 15\n",
        "lr = 2e-3\n",
        "seed = 42\n",
        "\n",
        "run_root = f\"{root_path}/runs_vae\"  # parent folder\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# optional: keep a summary list\n",
        "runs_summary = []\n",
        "\n",
        "for zdim in latent_dims:\n",
        "    for beta in betas:\n",
        "        run_name = f\"mnist_betaVAE_z{zdim}_beta{beta:g}_e{epochs}_lr{lr:g}_seed{seed}\"\n",
        "        print(\"\\n\" + \"=\"*90)\n",
        "        print(\"RUN:\", run_name)\n",
        "        print(\"=\"*90)\n",
        "\n",
        "        cfg = VAEConfig(\n",
        "            latent_dim=zdim,\n",
        "            beta=float(beta),\n",
        "            epochs=epochs,\n",
        "            lr=lr,\n",
        "            seed=seed,\n",
        "            run_root=run_root,\n",
        "            run_name=run_name,        # ensures separate folder per config\n",
        "            save_best_only=True,\n",
        "\n",
        "            # plot params\n",
        "            max_images_plot=16,\n",
        "            prior_n_plot=25,\n",
        "            latent_grid_size=20,\n",
        "            latent_grid_lim=3.0,\n",
        "            latent_scatter_max_points=5000,\n",
        "        )\n",
        "\n",
        "        model, history, run_dir = train_vae(cfg, dataloader_train, dataloader_val, device)\n",
        "\n",
        "        runs_summary.append({\n",
        "            \"run_name\": run_name,\n",
        "            \"run_dir\": run_dir,\n",
        "            \"latent_dim\": zdim,\n",
        "            \"beta\": beta,\n",
        "            \"final_val_loss\": history[\"val_loss\"][-1],\n",
        "            \"final_val_recon\": history[\"val_recon\"][-1],\n",
        "            \"final_val_kl\": history[\"val_kl\"][-1],\n",
        "        })\n",
        "\n",
        "print(\"\\nAll runs finished.\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T9O86MIQ-teX"
      },
      "source": [
        "# DDPM Training"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
